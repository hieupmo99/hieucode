name: Build and Deploy Pipeline

on:
  push:
    branches: [main]
    # Removed paths filter - now builds on every commit to main
  workflow_dispatch:
    inputs:
      run_crawler:
        description: 'Run crawler after build'
        required: false
        default: 'true'
        type: choice
        options:
          - 'true'
          - 'false'

jobs:
  # Job 1: Build Docker Images
  build-images:
    name: Build Docker Images
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Build Crawler Image
      run: |
        echo "ğŸ”¨ Building crawler image..."
        docker build -t hieucode-crawler:latest -f app/Dockerfile ./app
        echo "âœ… Crawler image built"
    
    - name: Build Spark Image
      run: |
        echo "ğŸ”¨ Building Spark image..."
        docker build -t hieucode-spark:latest -f spark/Dockerfile .
        echo "âœ… Spark image built"
    
    - name: Build Airflow Image
      run: |
        echo "ğŸ”¨ Building Airflow image..."
        docker build -t hieucode-airflow:latest -f airflow/Dockerfile .
        echo "âœ… Airflow image built"
    
    - name: Test Docker Compose Config
      run: |
        echo "âœ… Validating docker-compose.yml..."
        docker compose config > /dev/null
        echo "âœ… Docker compose configuration is valid"

  # Job 2: Deploy to Test Environment
  deploy-test:
    name: Deploy & Test Pipeline
    runs-on: ubuntu-latest
    needs: build-images
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Create required directories
      run: |
        mkdir -p app logs dags airflow
        chmod 777 logs
    
    - name: Start Kafka Cluster
      run: |
        echo "ğŸš€ Starting Kafka cluster..."
        docker compose up -d kafka-1 kafka-2 kafka-3
        echo "â³ Waiting for Kafka to be ready..."
        sleep 30
    
    - name: Verify Kafka Health
      run: |
        echo "ğŸ” Checking Kafka health..."
        docker compose ps
        docker compose logs kafka-1 | tail -20
        echo "âœ… Kafka cluster is running"
    
    - name: Create Kafka Topics
      run: |
        echo "ğŸ“Š Creating vnexpress_topic..."
        docker compose exec -T kafka-1 /opt/kafka/bin/kafka-topics.sh \
          --create \
          --topic vnexpress_topic \
          --bootstrap-server localhost:9092 \
          --partitions 3 \
          --replication-factor 2 \
          --if-not-exists || echo "Topic already exists"
        
        echo "âœ… Kafka topics ready"
    
    - name: Start Spark Streaming
      run: |
        echo "ğŸš€ Starting Spark..."
        docker compose up -d spark
        sleep 10
        docker compose logs spark | tail -20
        echo "âœ… Spark started"
    
    - name: Run Test Crawler
      if: github.event.inputs.run_crawler != 'false'
      run: |
        echo "ğŸ•·ï¸ Running test crawler..."
        docker compose run --rm crawler python3 mass_crawling.py || echo "Crawler test completed"
        
        echo "â³ Waiting for Spark to process..."
        sleep 15
        
        echo "âœ… Crawler test completed"
    
    - name: Verify Pipeline Results
      run: |
        echo "ğŸ” Checking results..."
        
        # Check if SQLite database was created
        if docker compose exec -T spark ls /opt/app/hieudb.db 2>/dev/null; then
          echo "âœ… Database created"
          docker compose exec -T spark sqlite3 /opt/app/hieudb.db "SELECT COUNT(*) as total FROM vnexpress;" || echo "Checking database..."
        else
          echo "âš ï¸  Database not found (may need more time)"
        fi
    
    - name: Show Logs
      if: always()
      run: |
        echo "ğŸ“‹ Kafka Logs:"
        docker compose logs kafka-1 --tail=50
        echo ""
        echo "ğŸ“‹ Spark Logs:"
        docker compose logs spark --tail=50
    
    - name: Cleanup
      if: always()
      run: |
        echo "ğŸ§¹ Cleaning up..."
        docker compose down -v
        echo "âœ… Cleanup complete"

  # Job 3: Deploy to Local Production
  deploy-production:
    name: Deploy to Local Production
    runs-on: self-hosted
    needs: [build-images, deploy-test]
    if: ${{ needs.build-images.result == 'success' && needs.deploy-test.result == 'success' }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Deploy to Production Folder
      run: |
        echo "ğŸš€ Deploying to ~/Documents/GitHub/action/..."
        cd ~/Documents/hieucode
        ./scripts/deploy.sh
        echo "âœ… Deployment completed!"
    
    - name: Verify Deployment
      run: |
        echo "ğŸ” Verifying deployment..."
        ls -la ~/Documents/GitHub/action/
        echo ""
        echo "âœ… Files deployed successfully!"
        echo "ğŸ“Š Dashboard: http://localhost:5000"
        echo "ğŸŒ¬ï¸  Airflow: http://localhost:8081"

  # Job 4: Notify Completion
  notify:
    name: Notify Deployment Status
    runs-on: ubuntu-latest
    needs: [build-images, deploy-test, deploy-production]
    if: always()
    
    steps:
    - name: Check Results
      run: |
        echo "============================================"
        echo "ğŸ“Š Pipeline Deployment Summary"
        echo "============================================"
        echo ""
        echo "Build Status: ${{ needs.build-images.result }}"
        echo "Deploy Test Status: ${{ needs.deploy-test.result }}"
        echo "Deploy Production Status: ${{ needs.deploy-production.result }}"
        echo ""
        
        if [ "${{ needs.build-images.result }}" == "success" ] && [ "${{ needs.deploy-test.result }}" == "success" ] && [ "${{ needs.deploy-production.result }}" == "success" ]; then
          echo "âœ… All jobs completed successfully!"
          echo ""
          echo "ğŸ¯ Deployment Complete:"
          echo "1. âœ… Images built and tested in GitHub Actions"
          echo "2. âœ… Code deployed to ~/Documents/GitHub/action/"
          echo "3. ğŸ“Š Dashboard running at http://localhost:5000"
          echo "4. ğŸŒ¬ï¸  Airflow running at http://localhost:8081"
        else
          echo "âš ï¸  Some jobs failed. Check logs above."
        fi
