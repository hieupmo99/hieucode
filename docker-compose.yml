

services:
  # ---------------------
  # Kafka Broker 1
  # ---------------------
  kafka-1:
    image: apache/kafka:latest
    hostname: kafka-1
    container_name: kafka-1
    ports:
      - "19092:19092"     # external
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093

      KAFKA_LISTENERS: PLAINTEXT://kafka-1:9092,CONTROLLER://kafka-1:9093,EXTERNAL://0.0.0.0:19092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-1:9092,EXTERNAL://localhost:19092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT

      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_NUM_PARTITIONS: 3
    networks:
      - kafka-net
    volumes:
      - kafka-data-1:/var/lib/kafka/data

  # ---------------------
  # Kafka Broker 2
  # ---------------------
  kafka-2:
    image: apache/kafka:latest
    hostname: kafka-2
    container_name: kafka-2
    ports:
      - "29092:29092"
    environment:
      KAFKA_NODE_ID: 2
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093

      KAFKA_LISTENERS: PLAINTEXT://kafka-2:9092,CONTROLLER://kafka-2:9093,EXTERNAL://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-2:9092,EXTERNAL://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT

      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_NUM_PARTITIONS: 3
    networks:
      - kafka-net
    volumes:
      - kafka-data-2:/var/lib/kafka/data

  # ---------------------
  # Kafka Broker 3
  # ---------------------
  kafka-3:
    image: apache/kafka:latest
    hostname: kafka-3
    container_name: kafka-3
    ports:
      - "39092:39092"
    environment:
      KAFKA_NODE_ID: 3
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093

      KAFKA_LISTENERS: PLAINTEXT://kafka-3:9092,CONTROLLER://kafka-3:9093,EXTERNAL://0.0.0.0:39092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-3:9092,EXTERNAL://localhost:39092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT

      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_NUM_PARTITIONS: 3
    networks:
      - kafka-net
    volumes:
      - kafka-data-3:/var/lib/kafka/data
  
  crawler:
    build:
      context: ./app
      dockerfile: Dockerfile
    container_name: crawler
    depends_on:
      - kafka-1
      - kafka-2
      - kafka-3
    networks:
      - kafka-net
    volumes:
      - ./app:/opt/app
    environment:
      KAFKA_BOOTSTRAP: kafka-1:9092,kafka-2:9092,kafka-3:9092
      KAFKA_TOPIC: vnexpress_topic
      DOCKER_ENV: "true"
    # Uncomment to auto-start crawler in Docker:
    # command: python /opt/app/mass_crawling.py
    # Or keep it idle and run manually:
    command: tail -f /dev/null

  # ---------------------
  # Kafka UI (optional)
  # ---------------------
  kafka-ui:
    image: provectuslabs/kafka-ui
    container_name: kafka-ui
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: kafka-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
    networks:
      - kafka-net

  # ---------------------
  # Spark Structured Streaming Container
  # ---------------------
  spark:
    build:
      context: .
      dockerfile: ./spark/Dockerfile
    container_name: spark
    depends_on:
      - kafka-1
      - kafka-2
      - kafka-3
    networks:
      - kafka-net
    volumes:
      - ./app:/opt/app
    environment:
      KAFKA_BOOTSTRAP: kafka-1:9092,kafka-2:9092,kafka-3:9092
      KAFKA_TOPIC: vnexpress_topic

  # ---------------------
  # PostgreSQL for Airflow
  # ---------------------
  postgres-airflow:
    image: postgres:15
    container_name: postgres-airflow
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-airflow-data:/var/lib/postgresql/data
    networks:
      - kafka-net
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 10s
      retries: 5
      start_period: 5s

  # ---------------------
  # Airflow Webserver
  # ---------------------
  airflow-webserver:
    build:
      context: .
      dockerfile: ./airflow/Dockerfile
    container_name: airflow-webserver
    depends_on:
      - postgres-airflow
    environment:
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres-airflow/airflow
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'false'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: 'true'
      AIRFLOW__WEBSERVER__SECRET_KEY: 'hieucode_secret_key_12345'
      AIRFLOW__CORE__FERNET_KEY: 'Zp3K7_Qx9YrXbNm4vCwS1tUaFgHjKlMnOpQrStUvWxY='
      KAFKA_BOOTSTRAP: kafka-1:9092,kafka-2:9092,kafka-3:9092
    volumes:
      - ./dags:/opt/airflow/dags
      - ./app:/opt/airflow/app
      - airflow-logs:/opt/airflow/logs
      - /var/run/docker.sock:/var/run/docker.sock  # Docker socket for service management
    ports:
      - "8081:8080"  # Changed to 8081 to avoid conflict with Kafka UI
    command: >
      bash -c "airflow db migrate &&
               airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com || true &&
               airflow webserver"
    networks:
      - kafka-net
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  # ---------------------
  # Airflow Scheduler
  # ---------------------
  airflow-scheduler:
    build:
      context: .
      dockerfile: ./airflow/Dockerfile
    container_name: airflow-scheduler
    depends_on:
      - postgres-airflow
      - airflow-webserver
    environment:
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres-airflow/airflow
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'false'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__CORE__FERNET_KEY: 'Zp3K7_Qx9YrXbNm4vCwS1tUaFgHjKlMnOpQrStUvWxY='
      KAFKA_BOOTSTRAP: kafka-1:9092,kafka-2:9092,kafka-3:9092
    volumes:
      - ./dags:/opt/airflow/dags
      - ./app:/opt/airflow/app
      - airflow-logs:/opt/airflow/logs
      - /var/run/docker.sock:/var/run/docker.sock  # Docker socket for service management
    command: airflow scheduler
    networks:
      - kafka-net
    healthcheck:
      test: ["CMD", "airflow", "jobs", "check", "--job-type", "SchedulerJob"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

volumes:
  kafka-data-1:
  kafka-data-2:
  kafka-data-3:
  postgres-airflow-data:
  airflow-logs:

networks:
  kafka-net:
    driver: bridge
